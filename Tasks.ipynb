{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51f4da44",
   "metadata": {},
   "source": [
    "# Project 2 - Multiple Myeloma Survival\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7d8e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import missingno as msno\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, BayesianRidge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.experimental import enable_iterative_imputer # N RETIRAR\n",
    "from sklearn.impute import SimpleImputer, IterativeImputer, KNNImputer\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "\n",
    "import os\n",
    "\n",
    "# Set white background for all plots\n",
    "plt.style.use('default')\n",
    "sns.set_style(\"white\")\n",
    "plt.rcParams['figure.facecolor'] = 'white'\n",
    "plt.rcParams['axes.facecolor'] = 'white'\n",
    "\n",
    "# Create plots directory\n",
    "os.makedirs(\"./plots\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a78a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8987bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_submission_file(predictions, filename):\n",
    "    \"\"\"\n",
    "    Create a submission file with predictions.\n",
    "    \n",
    "    Args:\n",
    "        predictions (array-like): The predicted values for SurvivalTime.\n",
    "        filename (str): The name of the output file.\n",
    "    \"\"\"\n",
    "    # Load the sample submission to get the 'Id' column structure\n",
    "    sample_submission = pd.read_csv('./data/sample_submission.csv')\n",
    "\n",
    "    # Ensure that predictions are a single column (reshape if necessary)\n",
    "    predictions = pd.Series(predictions).values\n",
    "    \n",
    "    # Create the submission DataFrame\n",
    "    submission = pd.DataFrame(columns=sample_submission.columns) \n",
    "    submission['id'] = range(len(predictions))\n",
    "    submission['0'] = predictions # Add the predictions to the 'SurvivalTime' column\n",
    "\n",
    "    # Save the DataFrame to CSV\n",
    "    os.makedirs(\"./results\", exist_ok=True)\n",
    "    submission.to_csv(f'./results/{filename}', index=False)\n",
    "\n",
    "    print(f\"File Created: ./results/{filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa04bfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_metric(y, y_hat, c):\n",
    "    \"\"\"\n",
    "    Censored Mean Squared Error calculation.\n",
    "    c = 0 for uncensored data points\n",
    "    c = 1 for censored data points\n",
    "    \n",
    "    Args:\n",
    "        y (array-like): True Survival Time values.\n",
    "        y_hat (array-like): Predicted Survival Time values.\n",
    "        c (array-like): Censoring indicators (0 for uncensored, 1 for censored).\n",
    "        \n",
    "    Returns:\n",
    "        float: The Censored Mean Squared Error.\n",
    "    \"\"\"\n",
    "    err = y-y_hat\n",
    "    err = (1-c)*err**2 + c*np.maximum(0,err)**2\n",
    "    return np.sum(err)/err.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40583574",
   "metadata": {},
   "source": [
    "## Task 1 - Setting the baseline\n",
    "\n",
    "### Task 1.1 - Data preparation and validation pipeline\n",
    "\n",
    "**1. Missing Values Analysis**\n",
    "\n",
    "- Visualized missing values using multiple methods (bar plot, heatmap, matrix, dendrogram)\n",
    "- Created comprehensive overview of data completeness\n",
    "- Identified patterns in missing data\n",
    "\n",
    "**2. Data Cleaning**\n",
    "\n",
    "- Dropped rows with missing `SurvivalTime` values\n",
    "- Removed columns containing missing data (baseline approach)\n",
    "- Excluded censored cases (where `Censored == 1`)\n",
    "- Retained only complete, uncensored observations\n",
    "\n",
    "**3. Feature Exploration**\n",
    "\n",
    "- Visualized feature relationships using pairplot\n",
    "- Analyzed correlations between Age, Gender, Stage, TreatmentType, and SurvivalTime\n",
    "- Examined distribution patterns across features\n",
    "\n",
    "**4. Data Preparation**\n",
    "\n",
    "- Defined feature matrix (X) by dropping target and identifier columns\n",
    "- Isolated target variable (y) as SurvivalTime\n",
    "- Preserved censoring indicator for potential future use\n",
    "\n",
    "**5. Validation Strategy Development**\n",
    "\n",
    "- Implemented train/validation/test split (64%/16%/20%)\n",
    "- Tested simple split approach with Linear Regression\n",
    "- Implemented 5-fold cross-validation for more robust evaluation\n",
    "- Compared both validation strategies (simple split vs. cross-validation)\n",
    "\n",
    "**6. Performance Evaluation**\n",
    "\n",
    "- Calculated MSE (Mean Squared Error) and cMSE (Censored MSE)\n",
    "- Evaluated model performance on validation and test sets\n",
    "- Compared cross-validation results to simple split results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33500ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize missing values using multiple missingno plots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.patch.set_facecolor('white')\n",
    "\n",
    "# Bar plot\n",
    "plt.subplot(2, 2, 1)\n",
    "msno.bar(df, ax=plt.gca())\n",
    "plt.title('Missing Values - Bar Plot')\n",
    "\n",
    "# Heatmap\n",
    "plt.subplot(2, 2, 2)\n",
    "msno.heatmap(df, ax=plt.gca())\n",
    "plt.title('Missing Values - Correlation Heatmap')\n",
    "\n",
    "# Matrix\n",
    "plt.subplot(2, 2, 3)\n",
    "msno.matrix(df, ax=plt.gca())\n",
    "plt.title('Missing Values - Matrix')\n",
    "\n",
    "# Dendrogram\n",
    "plt.subplot(2, 2, 4)\n",
    "msno.dendrogram(df, ax=plt.gca())\n",
    "plt.title('Missing Values - Dendrogram')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('./plots/task1.1_missing_values_overview.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n",
    "\n",
    "# Save each plot separately\n",
    "fig_bar = plt.figure(figsize=(10, 6))\n",
    "fig_bar.patch.set_facecolor('white')\n",
    "msno.bar(df, ax=plt.gca())\n",
    "plt.title('Missing Values - Bar Plot')\n",
    "plt.tight_layout()\n",
    "plt.savefig('./plots/task1.1_missing_values_bar.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "plt.close()\n",
    "\n",
    "fig_heatmap = plt.figure(figsize=(10, 6))\n",
    "fig_heatmap.patch.set_facecolor('white')\n",
    "msno.heatmap(df, ax=plt.gca())\n",
    "plt.title('Missing Values - Correlation Heatmap')\n",
    "plt.tight_layout()\n",
    "plt.savefig('./plots/task1.1_missing_values_heatmap.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "plt.close()\n",
    "\n",
    "fig_matrix = plt.figure(figsize=(10, 6))\n",
    "fig_matrix.patch.set_facecolor('white')\n",
    "msno.matrix(df, ax=plt.gca())\n",
    "plt.title('Missing Values - Matrix')\n",
    "plt.tight_layout()\n",
    "plt.savefig('./plots/task1.1_missing_values_matrix.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "plt.close()\n",
    "\n",
    "fig_dendrogram = plt.figure(figsize=(10, 6))\n",
    "fig_dendrogram.patch.set_facecolor('white')\n",
    "msno.dendrogram(df, ax=plt.gca())\n",
    "plt.title('Missing Values - Dendrogram')\n",
    "plt.tight_layout()\n",
    "plt.savefig('./plots/task1.1_missing_values_dendrogram.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0e6cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data cleaning for baseline model\n",
    "# 1. Drop rows with missing 'SurvivalTime' values\n",
    "df_cleaned = df[df['SurvivalTime'].notnull()].copy()\n",
    "\n",
    "# 2. Drop columns with missing data (baseline approach)\n",
    "df_cleaned = df_cleaned.dropna(axis=1)\n",
    "\n",
    "# 3. Drop censored cases (Censored == 1) for baseline\n",
    "# Censoring occurs when the exact time of an event (death/recurrence) is unknown\n",
    "df_cleaned = df_cleaned[df_cleaned['Censored'] == 0]\n",
    "\n",
    "print(f\"Original data points: {df.shape[0]}\")\n",
    "print(f\"Remaining data points after cleaning: {df_cleaned.shape[0]}\")\n",
    "print(f\"Data points dropped: {df.shape[0] - df_cleaned.shape[0]}\")\n",
    "print(f\"Columns retained: {list(df_cleaned.columns)}\")\n",
    "\n",
    "# Visualize cleaned data\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "fig.patch.set_facecolor('white')\n",
    "msno.matrix(df_cleaned)\n",
    "plt.title('Cleaned Data - Missing Values Matrix')\n",
    "plt.savefig('./plots/task1.1_cleaned_data_matrix.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77812ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature relationships\n",
    "# Note: Censored is excluded as it's a label indicator, not a predictive feature\n",
    "feature_cols = ['Age', 'Gender', 'Stage', 'TreatmentType', 'SurvivalTime']\n",
    "g = sns.pairplot(df_cleaned, vars=feature_cols)\n",
    "g.fig.patch.set_facecolor('white')\n",
    "plt.suptitle('Feature Relationships - Pairplot', y=1.01)\n",
    "plt.savefig('./plots/task1.1_feature_pairplot.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c57bc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the feature matrix (X) and target vector (y)\n",
    "X = df_cleaned.drop(['SurvivalTime', 'Censored','id'], axis=1)  # Drop target and censoring indicator\n",
    "y = df_cleaned['SurvivalTime']  # Target variable: survival time\n",
    "censored = df_cleaned['Censored']  # Censoring indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65d8d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First split: 80% train, 20% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Second split: further divide train into 80% train, 20% validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]} ({X_train.shape[0]/X.shape[0]*100:.1f}%)\")\n",
    "print(f\"Validation set size: {X_val.shape[0]} ({X_val.shape[0]/X.shape[0]*100:.1f}%)\")\n",
    "print(f\"Test set size: {X_test.shape[0]} ({X_test.shape[0]/X.shape[0]*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6032f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple train/validation/test approach (without cross-validation)\n",
    "print(\"=\" * 60)\n",
    "print(\"Simple Train/Validation/Test Split Approach\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Train model\n",
    "model_simple = LinearRegression()\n",
    "model_simple.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on validation set\n",
    "y_val_pred = model_simple.predict(X_val)\n",
    "val_mse = mean_squared_error(y_val, y_val_pred)\n",
    "print(f'Validation MSE: {val_mse:.4f}')\n",
    "\n",
    "# Evaluate on test set\n",
    "y_test_pred = model_simple.predict(X_test)\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "print(f'Test MSE: {test_mse:.4f}')\n",
    "\n",
    "# Calculate cMSE (all data points are uncensored, so c=0)\n",
    "test_cmse = error_metric(y_test, y_test_pred, 0)\n",
    "print(f'Test cMSE: {test_cmse:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d306c832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation approach (more robust)\n",
    "print(\"=\" * 60)\n",
    "print(\"Cross-Validation Approach (5-fold)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Train with cross-validation\n",
    "model_cv = LinearRegression()\n",
    "cv_scores = cross_val_score(model_cv, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "cv_mse_scores = -cv_scores  # Convert to positive MSE\n",
    "\n",
    "print(f\"Cross-validation MSE scores: {cv_mse_scores}\")\n",
    "print(f\"Average CV MSE: {np.mean(cv_mse_scores):.4f} (+/- {np.std(cv_mse_scores):.4f})\")\n",
    "\n",
    "# Fit model on full dataset\n",
    "model_cv.fit(X, y)\n",
    "y_pred_cv = model_cv.predict(X)\n",
    "\n",
    "# Calculate metrics\n",
    "train_mse = mean_squared_error(y, y_pred_cv)\n",
    "train_cmse = error_metric(y, y_pred_cv, censored)\n",
    "print(f\"Training MSE: {train_mse:.4f}\")\n",
    "print(f\"Training cMSE: {train_cmse:.4f}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef131ad",
   "metadata": {},
   "source": [
    "Comparing the Avarage MSE Cross validation value and the MSE value simple, with Cross Validation is more efficient without Cross Validation because in cross-validation, the model is trained and validated multiple times using different splits of the dataset. This means that the model gets to train on almost all of the data, which helps the model generalize better.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea25ecc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Baseline model with pipeline (scaling + regression)\n",
    "run_pipeline_test = bool(input(\"Run baseline model with pipeline? (y/n): \").lower() == \"y\")\n",
    "\n",
    "if run_pipeline_test:\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Pipeline Approach (Scaling + Linear Regression)\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Create fresh train/test split\n",
    "    X_train_pipe, X_test_pipe, y_train_pipe, y_test_pipe = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Build pipeline\n",
    "    pipeline = make_pipeline(\n",
    "        StandardScaler(),\n",
    "        LinearRegression()\n",
    "    )\n",
    "    \n",
    "    # Train and predict\n",
    "    pipeline.fit(X_train_pipe, y_train_pipe)\n",
    "    y_pred_pipe = pipeline.predict(X_test_pipe)\n",
    "    \n",
    "    # Evaluate\n",
    "    mse_pipe = mean_squared_error(y_test_pipe, y_pred_pipe)\n",
    "    cmse_pipe = error_metric(y_test_pipe, y_pred_pipe, 0)\n",
    "    \n",
    "    print(f\"Pipeline MSE: {mse_pipe:.4f}\")\n",
    "    print(f\"Pipeline cMSE: {cmse_pipe:.4f}\")\n",
    "    \n",
    "    # Comparison with previous approaches\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Comparison of All Approaches\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Simple Split - Test MSE:  {test_mse:.4f}\")\n",
    "    print(f\"Simple Split - Test cMSE: {test_cmse:.4f}\")\n",
    "    print(f\"Cross-Val    - Train MSE: {train_mse:.4f}\")\n",
    "    print(f\"Cross-Val    - Train cMSE: {train_cmse:.4f}\")\n",
    "    print(f\"Pipeline     - Test MSE:  {mse_pipe:.4f}\")\n",
    "    print(f\"Pipeline     - Test cMSE: {cmse_pipe:.4f}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    show_plots = bool(input(\"Visualize pipeline results? (y/n): \").lower() == \"y\")\n",
    "\n",
    "    if show_plots:\n",
    "        fig = plt.figure(figsize=(8, 6))\n",
    "        fig.patch.set_facecolor('white')\n",
    "        plt.scatter(y_test_pipe, y_pred_pipe, alpha=0.6)\n",
    "        plt.plot([y_test_pipe.min(), y_test_pipe.max()], \n",
    "                 [y_test_pipe.min(), y_test_pipe.max()], 'r--', lw=2)\n",
    "        plt.xlabel('True Survival Time')\n",
    "        plt.ylabel('Predicted Survival Time')\n",
    "        plt.title('Pipeline: True vs Predicted Survival Time')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"Pipeline test skipped.\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Comparison of All Approaches\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Simple Split - Test MSE:  {test_mse:.4f}\")\n",
    "    print(f\"Simple Split - Test cMSE: {test_cmse:.4f}\")\n",
    "    print(f\"Cross-Val    - Train MSE: {train_mse:.4f}\")\n",
    "    print(f\"Cross-Val    - Train cMSE: {train_cmse:.4f}\")\n",
    "    print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f2639e",
   "metadata": {},
   "source": [
    "### Task 1.2 - Learn the baseline model\n",
    "\n",
    "Train the final baseline model using cross-validation and generate predictions for submission.\n",
    "\n",
    "**1. Pipeline Construction**\n",
    "\n",
    "- Built baseline pipeline combining StandardScaler and Linear Regression\n",
    "- Ensured feature scaling for improved model performance\n",
    "- Created modular, reusable pipeline structure\n",
    "\n",
    "**2. Cross-Validation Training**\n",
    "\n",
    "- Performed 5-fold cross-validation for robust model evaluation\n",
    "- Calculated CV MSE scores across all folds\n",
    "- Computed mean and standard deviation of cross-validation performance\n",
    "\n",
    "**3. Final Model Training**\n",
    "\n",
    "- Fitted baseline pipeline on entire training dataset\n",
    "- Generated predictions on training data\n",
    "- Maximized use of available data for final model\n",
    "\n",
    "**4. Performance Metrics**\n",
    "\n",
    "- Calculated Training MSE (Mean Squared Error)\n",
    "- Calculated Training cMSE (Censored Mean Squared Error)\n",
    "- Established baseline performance benchmarks\n",
    "\n",
    "**5. Test Predictions & Submission**\n",
    "\n",
    "- Loaded test dataset and prepared features\n",
    "- Generated predictions for test samples\n",
    "- Created submission file for competition/evaluation\n",
    "\n",
    "**6. Model Visualization**\n",
    "\n",
    "- Created scatter plot comparing true vs predicted survival times\n",
    "- Generated boxplot for distribution comparison\n",
    "- Visualized model fit quality and prediction patterns\n",
    "- Saved individual plots for documentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7554c1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build baseline pipeline with scaling and Linear Regression\n",
    "baseline_pipeline = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    LinearRegression()\n",
    ")\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "print(\"=\" * 60)\n",
    "print(\"Baseline Model Training with Cross-Validation\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "cv_scores = cross_val_score(baseline_pipeline, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "cv_mse_scores = -cv_scores\n",
    "\n",
    "print(f\"CV MSE scores: {cv_mse_scores}\")\n",
    "print(f\"Average CV MSE: {np.mean(cv_mse_scores):.4f} (+/- {np.std(cv_mse_scores):.4f})\")\n",
    "\n",
    "# Fit on entire training dataset\n",
    "baseline_pipeline.fit(X, y)\n",
    "y_pred_baseline = baseline_pipeline.predict(X)\n",
    "\n",
    "# Evaluate final model\n",
    "mse_baseline = mean_squared_error(y, y_pred_baseline)\n",
    "cmse_baseline = error_metric(y, y_pred_baseline, censored)\n",
    "\n",
    "print(f\"\\nFinal Model Performance:\")\n",
    "print(f\"Training MSE:  {mse_baseline:.4f}\")\n",
    "print(f\"Training cMSE: {cmse_baseline:.4f}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79774b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions for test dataset and create submission file\n",
    "print(\"=\" * 60)\n",
    "print(\"Generating Submission File\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Load test data\n",
    "df_test = pd.read_csv('./data/test_data.csv')\n",
    "\n",
    "X_test_submission = df_test.drop(['id', 'GeneticRisk', 'TreatmentResponse', 'ComorbidityIndex'], axis=1)\n",
    "\n",
    "y_test_predictions = baseline_pipeline.predict(X_test_submission)\n",
    "\n",
    "create_submission_file(y_test_predictions, 'baseline-submission-01.csv')\n",
    "\n",
    "print(f\"Predictions generated for {len(y_test_predictions)} test samples\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f7ed9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model performance\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "fig.patch.set_facecolor('white')\n",
    "\n",
    "# Scatter plot: True vs Predicted\n",
    "axes[0].scatter(y, y_pred_baseline, alpha=0.6)\n",
    "axes[0].plot([y.min(), y.max()], [y.min(), y.max()], 'r--', lw=2, label='Ideal Prediction')\n",
    "axes[0].set_xlabel('True Survival Time')\n",
    "axes[0].set_ylabel('Predicted Survival Time')\n",
    "axes[0].set_title('Baseline Model: True vs Predicted Values')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Boxplot: Distribution comparison\n",
    "axes[1].boxplot([y, y_pred_baseline], tick_labels=[\"True Values\", \"Predicted Values\"])\n",
    "axes[1].set_ylabel('Survival Time')\n",
    "axes[1].set_title('Distribution Comparison')\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('./plots/task1.2_baseline_model_performance.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n",
    "\n",
    "# Save each plot separately\n",
    "fig_scatter = plt.figure(figsize=(8, 6))\n",
    "fig_scatter.patch.set_facecolor('white')\n",
    "plt.scatter(y, y_pred_baseline, alpha=0.6)\n",
    "plt.plot([y.min(), y.max()], [y.min(), y.max()], 'r--', lw=2, label='Ideal Prediction')\n",
    "plt.xlabel('True Survival Time')\n",
    "plt.ylabel('Predicted Survival Time')\n",
    "plt.title('Baseline Model: True vs Predicted Values')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('./plots/task1.2_baseline_scatter_plot.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "plt.close()\n",
    "\n",
    "fig_boxplot = plt.figure(figsize=(8, 6))\n",
    "fig_boxplot.patch.set_facecolor('white')\n",
    "plt.boxplot([y, y_pred_baseline], tick_labels=[\"True Values\", \"Predicted Values\"])\n",
    "plt.ylabel('Survival Time')\n",
    "plt.title('Distribution Comparison')\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.savefig('./plots/task1.2_baseline_boxplot.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a4bdfd",
   "metadata": {},
   "source": [
    "## Task 2 - Nonlinear models\n",
    "\n",
    "### Task 2.1 - Development\n",
    "\n",
    "Develop functions for training Polynomial Regression and k-Nearest Neighbors on the data prepared in Task 1.1, using the validation procedure determined in Task 1.1 and Task 1.2.\n",
    "\n",
    "Select model hyperparameters (polynomial degree and k) using cross-validation for model selection.\n",
    "\n",
    "**1. Polynomial Regression Function Development**\n",
    "\n",
    "- Created `train_polynomial_regression()` function with hyperparameter search\n",
    "- Implemented cross-validation for degree selection (testing degrees 1 to max_degree)\n",
    "- Added early stopping mechanism (stops after 2 consecutive iterations without improvement)\n",
    "- Returned best degree, trained model, and complete CV results dictionary\n",
    "\n",
    "**2. k-Nearest Neighbors Function Development**\n",
    "\n",
    "- Created `train_knn()` function with hyperparameter search\n",
    "- Implemented cross-validation for k selection (testing k from 1 to max_k)\n",
    "- Added early stopping mechanism for efficiency\n",
    "- Returned best k value, trained model, and complete CV results dictionary\n",
    "\n",
    "**3. Hyperparameter Selection**\n",
    "\n",
    "- Used 5-fold cross-validation for both models\n",
    "- Searched polynomial degrees from 1 to 10\n",
    "- Searched k values from 1 to 20\n",
    "- Tracked MSE scores with standard deviations for each hyperparameter\n",
    "\n",
    "**4. Model Training**\n",
    "\n",
    "- Trained Polynomial Regression with optimal degree on full dataset\n",
    "- Trained k-NN Regression with optimal k on full dataset\n",
    "- Generated predictions on training data for both models\n",
    "\n",
    "**5. Performance Evaluation**\n",
    "\n",
    "- Calculated training MSE for both models\n",
    "- Calculated training cMSE for both models\n",
    "- Compared performance against baseline expectations\n",
    "- Documented hyperparameter selection results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcaeedea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_polynomial_regression(X, y, max_degree=15, cv=5):\n",
    "    \"\"\"\n",
    "    Trains and evaluates Polynomial Regression with cross-validation for hyperparameter selection.\n",
    "    \n",
    "    Args:\n",
    "        X: Feature matrix\n",
    "        y: Target variable\n",
    "        max_degree: Maximum polynomial degree to test\n",
    "        cv: Number of cross-validation folds\n",
    "    \n",
    "    Returns:\n",
    "        best_degree: Optimal polynomial degree\n",
    "        best_model: Trained model with best degree\n",
    "        cv_results: Dictionary with all CV scores for each degree\n",
    "    \"\"\"\n",
    "    cv_results = {\n",
    "        'degrees': [],\n",
    "        'mean_scores': [],\n",
    "        'std_scores': [],\n",
    "        'all_scores': []\n",
    "    }\n",
    "    \n",
    "    best_score = -np.inf\n",
    "    best_degree = None\n",
    "    counter = 0\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"Polynomial Regression - Hyperparameter Selection\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Search over polynomial degrees\n",
    "    for degree in range(1, max_degree + 1):\n",
    "        model = make_pipeline(\n",
    "            StandardScaler(),\n",
    "            PolynomialFeatures(degree),\n",
    "            LinearRegression()\n",
    "        )\n",
    "        \n",
    "        # Cross-validation\n",
    "        scores = cross_val_score(model, X, y, cv=cv, scoring='neg_mean_squared_error')\n",
    "        mean_score = np.mean(scores)\n",
    "        std_score = np.std(scores)\n",
    "        \n",
    "        # Store results\n",
    "        cv_results['degrees'].append(degree)\n",
    "        cv_results['mean_scores'].append(-mean_score)\n",
    "        cv_results['std_scores'].append(std_score)\n",
    "        cv_results['all_scores'].append(-scores)\n",
    "        \n",
    "        print(f\"Degree {degree}: MSE = {-mean_score:.4f} (+/- {std_score:.4f})\")\n",
    "        \n",
    "        # Track best model\n",
    "        if mean_score > best_score:\n",
    "            best_score = mean_score\n",
    "            best_degree = degree\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "            if counter >= 2:\n",
    "                print(\"No improvement in 2 consecutive degrees, stopping early.\")\n",
    "                break\n",
    "\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Best Polynomial Degree: {best_degree}\")\n",
    "    print(f\"Best Cross-Validation MSE: {-best_score:.4f}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Train final model with best degree\n",
    "    best_model = make_pipeline(\n",
    "        StandardScaler(),\n",
    "        PolynomialFeatures(best_degree),\n",
    "        LinearRegression()\n",
    "    )\n",
    "    best_model.fit(X, y)\n",
    "    \n",
    "    return best_degree, best_model, cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59824583",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_knn(X, y, max_k=20, cv=5):\n",
    "    \"\"\"\n",
    "    Trains and evaluates k-Nearest Neighbors with cross-validation for hyperparameter selection.\n",
    "    \n",
    "    Args:\n",
    "        X: Feature matrix\n",
    "        y: Target variable\n",
    "        max_k: Maximum number of neighbors to test\n",
    "        cv: Number of cross-validation folds\n",
    "    \n",
    "    Returns:\n",
    "        best_k: Optimal number of neighbors\n",
    "        best_model: Trained model with best k\n",
    "        cv_results: Dictionary with all CV scores for each k\n",
    "    \"\"\"\n",
    "    cv_results = {\n",
    "        'k_values': [],\n",
    "        'mean_scores': [],\n",
    "        'std_scores': [],\n",
    "        'all_scores': []\n",
    "    }\n",
    "    \n",
    "    best_score = -np.inf\n",
    "    best_k = None\n",
    "    counter = 0\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"k-Nearest Neighbors - Hyperparameter Selection\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Search over k values\n",
    "    for k in range(1, max_k + 1):\n",
    "        model = make_pipeline(\n",
    "            StandardScaler(),\n",
    "            KNeighborsRegressor(n_neighbors=k)\n",
    "        )\n",
    "        \n",
    "        # Cross-validation\n",
    "        scores = cross_val_score(model, X, y, cv=cv, scoring='neg_mean_squared_error')\n",
    "        mean_score = np.mean(scores)\n",
    "        std_score = np.std(scores)\n",
    "        \n",
    "        # Store results\n",
    "        cv_results['k_values'].append(k)\n",
    "        cv_results['mean_scores'].append(-mean_score)\n",
    "        cv_results['std_scores'].append(std_score)\n",
    "        cv_results['all_scores'].append(-scores)\n",
    "        \n",
    "        print(f\"k = {k:2d}: MSE = {-mean_score:.4f} (+/- {std_score:.4f})\")\n",
    "        \n",
    "        # Track best model\n",
    "        if mean_score > best_score:\n",
    "            best_score = mean_score\n",
    "            best_k = k\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "            if counter >= 2:\n",
    "                print(\"No improvement in 2 consecutive k values, stopping early.\")\n",
    "                break\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Best k (Neighbors): {best_k}\")\n",
    "    print(f\"Best Cross-Validation MSE: {-best_score:.4f}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Train final model with best k\n",
    "    best_model = make_pipeline(\n",
    "        StandardScaler(),\n",
    "        KNeighborsRegressor(n_neighbors=best_k)\n",
    "    )\n",
    "    best_model.fit(X, y)\n",
    "    \n",
    "    return best_k, best_model, cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4d34f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Polynomial Regression with hyperparameter selection\n",
    "print(\"\\nTraining Polynomial Regression...\")\n",
    "best_poly_degree, poly_model, poly_cv_results = train_polynomial_regression(X, y, max_degree=10, cv=5)\n",
    "\n",
    "# Train k-NN Regressor with hyperparameter selection\n",
    "print(\"\\nTraining k-Nearest Neighbors...\")\n",
    "best_k, knn_model, knn_cv_results = train_knn(X, y, max_k=20, cv=5)\n",
    "\n",
    "# Generate predictions on training data\n",
    "y_pred_poly = poly_model.predict(X)\n",
    "y_pred_knn = knn_model.predict(X)\n",
    "\n",
    "# Calculate training metrics\n",
    "mse_poly_train = mean_squared_error(y, y_pred_poly)\n",
    "mse_knn_train = mean_squared_error(y, y_pred_knn)\n",
    "cmse_poly_train = error_metric(y, y_pred_poly, censored)\n",
    "cmse_knn_train = error_metric(y, y_pred_knn, censored)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Training Performance Summary\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Polynomial Regression (degree={best_poly_degree}):\")\n",
    "print(f\"  Training MSE:  {mse_poly_train:.4f}\")\n",
    "print(f\"  Training cMSE: {cmse_poly_train:.4f}\")\n",
    "print(f\"\\nk-NN Regression (k={best_k}):\")\n",
    "print(f\"  Training MSE:  {mse_knn_train:.4f}\")\n",
    "print(f\"  Training cMSE: {cmse_knn_train:.4f}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0357e73a",
   "metadata": {},
   "source": [
    "### Task 2.2 - Evaluation\n",
    "\n",
    "Evaluate the models developed in Task 2.1 against the baseline. Analysis backed with evidence through tables displaying different models and their metrics (max, min, mean error, and standard deviation).\n",
    "\n",
    "**1. Comprehensive Model Comparison**\n",
    "\n",
    "- Created comparison table with baseline, polynomial regression, and k-NN models\n",
    "- Included hyperparameter configurations for each model\n",
    "- Displayed min, max, mean, and standard deviation of errors\n",
    "- Identified best performing model based on mean cross-validation error\n",
    "\n",
    "**2. Hyperparameter Tuning Visualization**\n",
    "\n",
    "- Plotted polynomial degree vs MSE with confidence intervals\n",
    "- Plotted k-value vs MSE with confidence intervals\n",
    "- Marked optimal hyperparameters with vertical lines\n",
    "- Showed performance trends across hyperparameter ranges\n",
    "\n",
    "**3. Model Predictions Comparison**\n",
    "\n",
    "- Created scatter plots of true vs predicted values for all three models\n",
    "- Displayed MSE on each plot for direct comparison\n",
    "- Included ideal prediction line (y=x) as reference\n",
    "- Generated combined and individual visualization plots\n",
    "\n",
    "**4. Statistical Analysis**\n",
    "\n",
    "- Computed cross-validation statistics for each model\n",
    "- Analyzed variance in predictions across folds\n",
    "- Compared model stability through standard deviation metrics\n",
    "- Evaluated improvement over baseline model\n",
    "\n",
    "**5. Test Set Predictions**\n",
    "\n",
    "- Selected best performing model based on CV results\n",
    "- Generated predictions for test dataset\n",
    "- Created submission file for evaluation\n",
    "- Documented model selection rationale\n",
    "\n",
    "**6. Results Documentation**\n",
    "\n",
    "- Saved all comparison plots with task-specific naming\n",
    "- Generated separate plots for polynomial and k-NN tuning\n",
    "- Created individual prediction visualizations for each model\n",
    "- Documented complete evaluation workflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d501e66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive model comparison table\n",
    "print(\"\\n\" + \"=\" * 88)\n",
    "print(\"MODEL EVALUATION - COMPARISON TABLE\")\n",
    "print(\"=\" * 88)\n",
    "\n",
    "# Collect all model results\n",
    "models_data = []\n",
    "\n",
    "# Baseline model (from Task 1.2)\n",
    "baseline_cv_scores = cross_val_score(baseline_pipeline, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "baseline_errors = -baseline_cv_scores\n",
    "models_data.append({\n",
    "    'Model': 'Baseline (Linear Regression)',\n",
    "    'Hyperparameter': 'N/A',\n",
    "    'Min Error': np.min(baseline_errors),\n",
    "    'Max Error': np.max(baseline_errors),\n",
    "    'Mean Error': np.mean(baseline_errors),\n",
    "    'Std Error': np.std(baseline_errors)\n",
    "})\n",
    "\n",
    "# Polynomial Regression\n",
    "poly_errors = np.array(poly_cv_results['mean_scores'])\n",
    "best_poly_idx = poly_cv_results['degrees'].index(best_poly_degree)\n",
    "best_poly_scores = poly_cv_results['all_scores'][best_poly_idx]\n",
    "models_data.append({\n",
    "    'Model': 'Polynomial Regression',\n",
    "    'Hyperparameter': f'degree={best_poly_degree}',\n",
    "    'Min Error': np.min(best_poly_scores),\n",
    "    'Max Error': np.max(best_poly_scores),\n",
    "    'Mean Error': np.mean(best_poly_scores),\n",
    "    'Std Error': np.std(best_poly_scores)\n",
    "})\n",
    "\n",
    "# k-NN Regression\n",
    "knn_errors = np.array(knn_cv_results['mean_scores'])\n",
    "best_knn_idx = knn_cv_results['k_values'].index(best_k)\n",
    "best_knn_scores = knn_cv_results['all_scores'][best_knn_idx]\n",
    "models_data.append({\n",
    "    'Model': 'k-NN Regression',\n",
    "    'Hyperparameter': f'k={best_k}',\n",
    "    'Min Error': np.min(best_knn_scores),\n",
    "    'Max Error': np.max(best_knn_scores),\n",
    "    'Mean Error': np.mean(best_knn_scores),\n",
    "    'Std Error': np.std(best_knn_scores)\n",
    "})\n",
    "\n",
    "# Create comparison DataFrame\n",
    "comparison_df = pd.DataFrame(models_data)\n",
    "comparison_df = comparison_df.round(4)\n",
    "\n",
    "print(comparison_df.to_string(index=False))\n",
    "print(\"=\" * 88)\n",
    "\n",
    "# Identify best model\n",
    "best_model_idx = comparison_df['Mean Error'].idxmin()\n",
    "best_model_name = comparison_df.loc[best_model_idx, 'Model']\n",
    "print(f\"Best Model: {best_model_name}\")\n",
    "print(f\"Mean CV Error: {comparison_df.loc[best_model_idx, 'Mean Error']:.4f}\")\n",
    "print(\"=\" * 88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f37e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize hyperparameter tuning results\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "fig.patch.set_facecolor('white')\n",
    "\n",
    "# Polynomial Regression: Degree vs MSE\n",
    "axes[0].plot(poly_cv_results['degrees'], poly_cv_results['mean_scores'], 'b-o', linewidth=2, markersize=6)\n",
    "axes[0].fill_between(\n",
    "    poly_cv_results['degrees'],\n",
    "    np.array(poly_cv_results['mean_scores']) - np.array(poly_cv_results['std_scores']),\n",
    "    np.array(poly_cv_results['mean_scores']) + np.array(poly_cv_results['std_scores']),\n",
    "    alpha=0.2\n",
    ")\n",
    "axes[0].axvline(x=best_poly_degree, color='r', linestyle='--', label=f'Best degree = {best_poly_degree}')\n",
    "axes[0].set_xlabel('Polynomial Degree')\n",
    "axes[0].set_ylabel('Cross-Validation MSE')\n",
    "axes[0].set_title('Polynomial Regression - Hyperparameter Tuning')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# k-NN: k vs MSE\n",
    "axes[1].plot(knn_cv_results['k_values'], knn_cv_results['mean_scores'], 'g-o', linewidth=2, markersize=6)\n",
    "axes[1].fill_between(\n",
    "    knn_cv_results['k_values'],\n",
    "    np.array(knn_cv_results['mean_scores']) - np.array(knn_cv_results['std_scores']),\n",
    "    np.array(knn_cv_results['mean_scores']) + np.array(knn_cv_results['std_scores']),\n",
    "    alpha=0.2\n",
    ")\n",
    "axes[1].axvline(x=best_k, color='r', linestyle='--', label=f'Best k = {best_k}')\n",
    "axes[1].set_xlabel('Number of Neighbors (k)')\n",
    "axes[1].set_ylabel('Cross-Validation MSE')\n",
    "axes[1].set_title('k-NN Regression - Hyperparameter Tuning')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('./plots/task2.2_hyperparameter_tuning.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n",
    "\n",
    "# Save individual plots separately\n",
    "# Polynomial Regression plot\n",
    "fig_poly = plt.figure(figsize=(8, 6))\n",
    "fig_poly.patch.set_facecolor('white')\n",
    "plt.plot(poly_cv_results['degrees'], poly_cv_results['mean_scores'], 'b-o', linewidth=2, markersize=6)\n",
    "plt.fill_between(\n",
    "    poly_cv_results['degrees'],\n",
    "    np.array(poly_cv_results['mean_scores']) - np.array(poly_cv_results['std_scores']),\n",
    "    np.array(poly_cv_results['mean_scores']) + np.array(poly_cv_results['std_scores']),\n",
    "    alpha=0.2\n",
    ")\n",
    "plt.axvline(x=best_poly_degree, color='r', linestyle='--', label=f'Best degree = {best_poly_degree}')\n",
    "plt.xlabel('Polynomial Degree')\n",
    "plt.ylabel('Cross-Validation MSE')\n",
    "plt.title('Polynomial Regression - Hyperparameter Tuning')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('./plots/task2.2_polynomial_tuning.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "plt.close()\n",
    "\n",
    "# k-NN plot\n",
    "fig_knn = plt.figure(figsize=(8, 6))\n",
    "fig_knn.patch.set_facecolor('white')\n",
    "plt.plot(knn_cv_results['k_values'], knn_cv_results['mean_scores'], 'g-o', linewidth=2, markersize=6)\n",
    "plt.fill_between(\n",
    "    knn_cv_results['k_values'],\n",
    "    np.array(knn_cv_results['mean_scores']) - np.array(knn_cv_results['std_scores']),\n",
    "    np.array(knn_cv_results['mean_scores']) + np.array(knn_cv_results['std_scores']),\n",
    "    alpha=0.2\n",
    ")\n",
    "plt.axvline(x=best_k, color='r', linestyle='--', label=f'Best k = {best_k}')\n",
    "plt.xlabel('Number of Neighbors (k)')\n",
    "plt.ylabel('Cross-Validation MSE')\n",
    "plt.title('k-NN Regression - Hyperparameter Tuning')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('./plots/task2.2_knn_tuning.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf5c9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions for all models\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "fig.patch.set_facecolor('white')\n",
    "\n",
    "# Baseline predictions\n",
    "axes[0].scatter(y, y_pred_baseline, alpha=0.6, color='blue')\n",
    "axes[0].plot([y.min(), y.max()], [y.min(), y.max()], 'r--', lw=2)\n",
    "axes[0].set_xlabel('True Survival Time')\n",
    "axes[0].set_ylabel('Predicted Survival Time')\n",
    "axes[0].set_title(f'Baseline Model\\nMSE: {mse_baseline:.4f}')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Polynomial predictions\n",
    "axes[1].scatter(y, y_pred_poly, alpha=0.6, color='green')\n",
    "axes[1].plot([y.min(), y.max()], [y.min(), y.max()], 'r--', lw=2)\n",
    "axes[1].set_xlabel('True Survival Time')\n",
    "axes[1].set_ylabel('Predicted Survival Time')\n",
    "axes[1].set_title(f'Polynomial Regression (degree={best_poly_degree})\\nMSE: {mse_poly_train:.4f}')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# k-NN predictions\n",
    "axes[2].scatter(y, y_pred_knn, alpha=0.6, color='orange')\n",
    "axes[2].plot([y.min(), y.max()], [y.min(), y.max()], 'r--', lw=2)\n",
    "axes[2].set_xlabel('True Survival Time')\n",
    "axes[2].set_ylabel('Predicted Survival Time')\n",
    "axes[2].set_title(f'k-NN Regression (k={best_k})\\nMSE: {mse_knn_train:.4f}')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('./plots/task2.2_model_predictions_comparison.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n",
    "\n",
    "# Save individual prediction plots separately\n",
    "# Polynomial Regression predictions\n",
    "fig_poly_pred = plt.figure(figsize=(8, 6))\n",
    "fig_poly_pred.patch.set_facecolor('white')\n",
    "plt.scatter(y, y_pred_poly, alpha=0.6, color='green')\n",
    "plt.plot([y.min(), y.max()], [y.min(), y.max()], 'r--', lw=2)\n",
    "plt.xlabel('True Survival Time')\n",
    "plt.ylabel('Predicted Survival Time')\n",
    "plt.title(f'Polynomial Regression (degree={best_poly_degree})\\nMSE: {mse_poly_train:.4f}')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('./plots/task2.2_polynomial_predictions.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "plt.close()\n",
    "\n",
    "# k-NN predictions\n",
    "fig_knn_pred = plt.figure(figsize=(8, 6))\n",
    "fig_knn_pred.patch.set_facecolor('white')\n",
    "plt.scatter(y, y_pred_knn, alpha=0.6, color='orange')\n",
    "plt.plot([y.min(), y.max()], [y.min(), y.max()], 'r--', lw=2)\n",
    "plt.xlabel('True Survival Time')\n",
    "plt.ylabel('Predicted Survival Time')\n",
    "plt.title(f'k-NN Regression (k={best_k})\\nMSE: {mse_knn_train:.4f}')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('./plots/task2.2_knn_predictions.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9758a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions for test dataset and create submission file\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Generating Submission File for Task 2\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Load test data\n",
    "df_test_task2 = pd.read_csv('./data/test_data.csv')\n",
    "X_test_task2 = df_test_task2.drop(['id', 'GeneticRisk', 'TreatmentResponse', 'ComorbidityIndex'], axis=1)\n",
    "\n",
    "# Determine which model to submit based on best CV performance\n",
    "if comparison_df.loc[best_model_idx, 'Model'] == 'Polynomial Regression':\n",
    "    best_predictions = poly_model.predict(X_test_task2)\n",
    "    model_info = f\"Polynomial Regression (degree={best_poly_degree})\"\n",
    "elif comparison_df.loc[best_model_idx, 'Model'] == 'k-NN Regression':\n",
    "    best_predictions = knn_model.predict(X_test_task2)\n",
    "    model_info = f\"k-NN Regression (k={best_k})\"\n",
    "else:\n",
    "    # If baseline is still best, use polynomial as nonlinear alternative\n",
    "    best_predictions = poly_model.predict(X_test_task2)\n",
    "    model_info = f\"Polynomial Regression (degree={best_poly_degree})\"\n",
    "\n",
    "print(f\"Best model selected: {model_info}\")\n",
    "\n",
    "# Create submission file\n",
    "create_submission_file(best_predictions, 'Nonlinear-submission-01.csv')\n",
    "\n",
    "print(f\"Predictions generated for {len(best_predictions)} test samples\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5140a5",
   "metadata": {},
   "source": [
    "## Task 3 - Handling missing data\n",
    "\n",
    "### Task 3.1 - Missing data imputation\n",
    "\n",
    "**1. Data Preparation**\n",
    "\n",
    "- Load original dataset with missing values\n",
    "- Analyze missing value patterns\n",
    "- Prepare feature matrix (X) and target variable (y) with missing data intact\n",
    "\n",
    "**2. Imputation Strategies**\n",
    "\n",
    "- **Mean Imputation**: Replace missing values with column means\n",
    "- **KNN Imputation**: Use k-nearest neighbors to estimate missing values\n",
    "- **Iterative Imputation**: Use Bayesian Ridge regression for multivariate imputation\n",
    "\n",
    "**3. Model Evaluation**\n",
    "\n",
    "- Train baseline Linear Regression model on each imputed dataset\n",
    "- Evaluate using both train/test split and cross-validation approaches\n",
    "- Compare performance using cMSE (Censored Mean Squared Error)\n",
    "- Test with KNN Regression model for comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5bc319",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = df.isnull().sum()\n",
    "print(\"Missing values per column:\")\n",
    "print(missing_values)\n",
    "print()\n",
    "\n",
    "X_missingValues = df.drop(['SurvivalTime', 'Censored', 'id'], axis=1)\n",
    "y_missingValues = df['SurvivalTime']\n",
    "censored_missingValues = df['Censored']\n",
    "\n",
    "print(f\"Total data points: {df.shape[0]}\")\n",
    "print(f\"Features shape: {X_missingValues.shape}\")\n",
    "print(f\"Target shape: {y_missingValues.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08147da9",
   "metadata": {},
   "source": [
    "#### Strategy 1: Mean Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb3562f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "X_imputed_mean = mean_imputer.fit_transform(X_missingValues)\n",
    "print(f\"Features imputed: {X_imputed_mean.shape}\")\n",
    "\n",
    "y_imputed_mean = mean_imputer.fit_transform(y_missingValues.values.reshape(-1, 1))\n",
    "print(f\"Target imputed: {y_imputed_mean.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0019be0",
   "metadata": {},
   "source": [
    "#### Strategy 2: KNN Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fac648e",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_imputer = KNNImputer(n_neighbors=5)\n",
    "\n",
    "X_imputed_knn = knn_imputer.fit_transform(X_missingValues)\n",
    "print(f\"Features imputed: {X_imputed_knn.shape}\")\n",
    "\n",
    "y_imputed_knn = knn_imputer.fit_transform(y_missingValues.values.reshape(-1, 1))\n",
    "print(f\"Target imputed: {y_imputed_knn.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fe21d5",
   "metadata": {},
   "source": [
    "#### Strategy 3: Iterative Imputation (Bayesian Ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87726935",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterative_imputer = IterativeImputer(estimator=BayesianRidge(), max_iter=10, random_state=42)\n",
    "\n",
    "X_imputed_iterative = iterative_imputer.fit_transform(X_missingValues)\n",
    "print(f\"Features imputed: {X_imputed_iterative.shape}\")\n",
    "\n",
    "y_imputed_iterative = iterative_imputer.fit_transform(y_missingValues.values.reshape(-1, 1))\n",
    "print(f\"Target imputed: {y_imputed_iterative.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d774f0eb",
   "metadata": {},
   "source": [
    "#### Evaluation 1: Baseline Linear Regression with Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc83baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model_split = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    LinearRegression()\n",
    ")\n",
    "\n",
    "def evaluate_imputation_split(X_imputed, y_imputed, imputation_name):\n",
    "\n",
    "    y_with_censored = np.column_stack((y_imputed, censored_missingValues))\n",
    "    \n",
    "    X_train, X_test, y_train_censored, y_test_censored = train_test_split(\n",
    "        X_imputed, y_with_censored, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    y_train = y_train_censored[:, 0]\n",
    "    y_test = y_test_censored[:, 0]\n",
    "    censored_test = y_test_censored[:, 1]\n",
    "    \n",
    "    baseline_model_split.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = baseline_model_split.predict(X_test)\n",
    "    \n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    cmse = error_metric(y_test, y_pred, censored_test)\n",
    "    \n",
    "    print(f\"\\n{imputation_name}:\")\n",
    "    print(f\"  MSE:  {mse:.4f}\")\n",
    "    print(f\"  cMSE: {cmse:.4f}\")\n",
    "    \n",
    "    fig = plt.figure(figsize=(8, 6))\n",
    "    fig.patch.set_facecolor('white')\n",
    "    plt.scatter(y_test, y_pred, alpha=0.6)\n",
    "    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "    plt.xlabel('True Survival Time')\n",
    "    plt.ylabel('Predicted Survival Time')\n",
    "    plt.title(f'{imputation_name} - Train/Test Split')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'./plots/task3.1_{imputation_name.lower().replace(\" \", \"_\")}_split.png', \n",
    "                dpi=300, bbox_inches='tight', facecolor='white')\n",
    "    plt.show()\n",
    "    \n",
    "    return cmse\n",
    "\n",
    "cmse_mean_split = evaluate_imputation_split(X_imputed_mean, y_imputed_mean, \"Mean Imputation\")\n",
    "cmse_knn_split = evaluate_imputation_split(X_imputed_knn, y_imputed_knn, \"KNN Imputation\")\n",
    "cmse_iter_split = evaluate_imputation_split(X_imputed_iterative, y_imputed_iterative, \"Iterative Imputation\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Summary - Train/Test Split:\")\n",
    "print(f\"  Mean Imputation:      cMSE = {cmse_mean_split:.4f}\")\n",
    "print(f\"  KNN Imputation:       cMSE = {cmse_knn_split:.4f}\")\n",
    "print(f\"  Iterative Imputation: cMSE = {cmse_iter_split:.4f}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fff10ae",
   "metadata": {},
   "source": [
    "#### Evaluation 2: Baseline Linear Regression with Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221cb422",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model_cv = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    LinearRegression()\n",
    ")\n",
    "\n",
    "def evaluate_imputation_cv(X_imputed, y_imputed, censored, imputation_name, cv=5):\n",
    "\n",
    "    cv_scores = cross_val_score(baseline_model_cv, X_imputed, y_imputed, \n",
    "                                cv=cv, scoring='neg_mean_squared_error')\n",
    "    mse_scores = -cv_scores\n",
    "    \n",
    "    baseline_model_cv.fit(X_imputed, y_imputed)\n",
    "    y_pred = baseline_model_cv.predict(X_imputed)\n",
    "    \n",
    "    cmse = error_metric(y_imputed, y_pred, censored)\n",
    "    \n",
    "    print(f\"\\n{imputation_name}:\")\n",
    "    print(f\"  CV MSE scores: {mse_scores}\")\n",
    "    print(f\"  Mean CV MSE:   {np.mean(mse_scores):.4f} (+/- {np.std(mse_scores):.4f})\")\n",
    "    print(f\"  Overall cMSE:  {cmse:.4f}\")\n",
    "    \n",
    "    fig = plt.figure(figsize=(8, 6))\n",
    "    fig.patch.set_facecolor('white')\n",
    "    plt.scatter(y_imputed, y_pred, alpha=0.6)\n",
    "    plt.plot([y_imputed.min(), y_imputed.max()], [y_imputed.min(), y_imputed.max()], 'r--', lw=2)\n",
    "    plt.xlabel('True Survival Time')\n",
    "    plt.ylabel('Predicted Survival Time')\n",
    "    plt.title(f'{imputation_name} - Cross-Validation')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'./plots/task3.1_{imputation_name.lower().replace(\" \", \"_\")}_cv.png', \n",
    "                dpi=300, bbox_inches='tight', facecolor='white')\n",
    "    plt.show()\n",
    "    \n",
    "    return cmse\n",
    "\n",
    " # TODO: pensar se faz sentido colocar aqui o censored = 0, a unica coisa que muda  o valor do cMSE mas a concluso  a mesma\n",
    "censored_reshaped = censored_missingValues.values.reshape(-1, 1)\n",
    "cmse_mean_cv = evaluate_imputation_cv(X_imputed_mean, y_imputed_mean, censored_reshaped, \"Mean Imputation\")\n",
    "cmse_knn_cv = evaluate_imputation_cv(X_imputed_knn, y_imputed_knn, censored_reshaped, \"KNN Imputation\")\n",
    "cmse_iter_cv = evaluate_imputation_cv(X_imputed_iterative, y_imputed_iterative, censored_reshaped, \"Iterative Imputation\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Summary - Cross-Validation:\")\n",
    "print(f\"  Mean Imputation:      cMSE = {cmse_mean_cv:.4f}\")\n",
    "print(f\"  KNN Imputation:       cMSE = {cmse_knn_cv:.4f}\")\n",
    "print(f\"  Iterative Imputation: cMSE = {cmse_iter_cv:.4f}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635c6fab",
   "metadata": {},
   "source": [
    "#### Evaluation 3: KNN Regression Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d08e5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_regression_model = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    KNeighborsRegressor()\n",
    ")\n",
    "\n",
    "def evaluate_knn_regression(X_imputed, y_imputed, censored, imputation_name, max_k=20, cv=5):\n",
    "\n",
    "    best_score = np.inf\n",
    "    best_k = None\n",
    "    \n",
    "    for k in range(1, max_k + 1):\n",
    "        knn_regression_model.set_params(kneighborsregressor__n_neighbors=k)\n",
    "        scores = cross_val_score(knn_regression_model, X_imputed, y_imputed, \n",
    "                                cv=cv, scoring='neg_mean_squared_error')\n",
    "        mean_mse = -np.mean(scores)\n",
    "        \n",
    "        if mean_mse < best_score:\n",
    "            best_score = mean_mse\n",
    "            best_k = k\n",
    "    \n",
    "    knn_regression_model.set_params(kneighborsregressor__n_neighbors=best_k)\n",
    "    knn_regression_model.fit(X_imputed, y_imputed)\n",
    "    y_pred = knn_regression_model.predict(X_imputed)\n",
    "    \n",
    "    cmse = error_metric(y_imputed, y_pred, censored)\n",
    "    \n",
    "    print(f\"\\n{imputation_name}:\")\n",
    "    print(f\"  Best k:    {best_k}\")\n",
    "    print(f\"  Best cMSE: {cmse:.4f}\")\n",
    "    \n",
    "    return best_k, cmse\n",
    "\n",
    "censored_reshaped = censored_missingValues.values.reshape(-1, 1)\n",
    "k_mean, cmse_mean_knn = evaluate_knn_regression(X_imputed_mean, y_imputed_mean, censored_reshaped, \"Mean Imputation\")\n",
    "k_knn, cmse_knn_knn = evaluate_knn_regression(X_imputed_knn, y_imputed_knn, censored_reshaped, \"KNN Imputation\")\n",
    "k_iter, cmse_iter_knn = evaluate_knn_regression(X_imputed_iterative, y_imputed_iterative, censored_reshaped, \"Iterative Imputation\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Summary - KNN Regression:\")\n",
    "print(f\"  Mean Imputation:      cMSE = {cmse_mean_knn:.4f} (k={k_mean})\")\n",
    "print(f\"  KNN Imputation:       cMSE = {cmse_knn_knn:.4f} (k={k_knn})\")\n",
    "print(f\"  Iterative Imputation: cMSE = {cmse_iter_knn:.4f} (k={k_iter})\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2b01e1",
   "metadata": {},
   "source": [
    "#### Final Comparison and Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbfc8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 88)\n",
    "imputation_comparison = pd.DataFrame({\n",
    "    'Imputation Strategy': ['Mean', 'KNN', 'Iterative'],\n",
    "    'cMSE (Train/Test)': [cmse_mean_split, cmse_knn_split, cmse_iter_split],\n",
    "    'cMSE (Cross-Val)': [cmse_mean_cv, cmse_knn_cv, cmse_iter_cv],\n",
    "    'cMSE (KNN Model)': [cmse_mean_knn, cmse_knn_knn, cmse_iter_knn],\n",
    "    'Best k (KNN Model)': [k_mean, k_knn, k_iter]\n",
    "})\n",
    "\n",
    "print(imputation_comparison.to_string(index=False))\n",
    "print(\"=\" * 88)\n",
    "\n",
    "best_idx_cv = imputation_comparison['cMSE (Cross-Val)'].idxmin()\n",
    "best_strategy = imputation_comparison.loc[best_idx_cv, 'Imputation Strategy']\n",
    "best_cmse = imputation_comparison.loc[best_idx_cv, 'cMSE (Cross-Val)']\n",
    "\n",
    "print(f\"Best Imputation Strategy: {best_strategy}\")\n",
    "print(f\"Best Cross-Validation cMSE: {best_cmse:.4f}\")\n",
    "print(\"=\" * 88)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fa046a",
   "metadata": {},
   "source": [
    "### Task 3.2 - Train models that do not require imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c6cbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_missing = pd.read_csv('./data/train_data.csv')\n",
    "\n",
    "df_task3_2 = df_with_missing[df_with_missing['SurvivalTime'].notnull()].copy()\n",
    "\n",
    "X_with_missing = df_task3_2.drop(['SurvivalTime', 'Censored', 'id'], axis=1)\n",
    "y_with_missing = df_task3_2['SurvivalTime']\n",
    "censored_with_missing = df_task3_2['Censored']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01d71c8",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbb8b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tree = X_with_missing.fillna(-999)\n",
    "\n",
    "param_grid_tree = {\n",
    "    'max_depth': [5, 10, 15, 20, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "tree_model = DecisionTreeRegressor(random_state=42)\n",
    "grid_search_tree = GridSearchCV(\n",
    "    tree_model,\n",
    "    param_grid_tree,\n",
    "    cv=5,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search_tree.fit(X_tree, y_with_missing)\n",
    "\n",
    "print(f\"\\nBest Parameters: {grid_search_tree.best_params_}\")\n",
    "print(f\"Best CV MSE: {-grid_search_tree.best_score_:.4f}\")\n",
    "\n",
    "best_tree_model = grid_search_tree.best_estimator_\n",
    "y_pred_tree = best_tree_model.predict(X_tree)\n",
    "\n",
    "mse_tree = mean_squared_error(y_with_missing, y_pred_tree)\n",
    "cmse_tree = error_metric(y_with_missing, y_pred_tree, censored_with_missing)\n",
    "\n",
    "print(f\"\\nDecision Tree Performance:\")\n",
    "print(f\"Training MSE:  {mse_tree:.4f}\")\n",
    "print(f\"Training cMSE: {cmse_tree:.4f}\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "sns.scatterplot(x=y_with_missing, y=y_pred_tree, alpha=0.6)\n",
    "plt.plot([y_with_missing.min(), y_with_missing.max()],\n",
    "         [y_with_missing.min(), y_with_missing.max()],\n",
    "         color='red', linestyle='--')\n",
    "plt.xlabel(\"Valores Observados\")\n",
    "plt.ylabel(\"Valores Preditos\")\n",
    "plt.title(\"Decision Tree: Observados vs Preditos\")\n",
    "plt.show()\n",
    "\n",
    "# -------------------------------\n",
    "# 2 Resduos\n",
    "# -------------------------------\n",
    "residuals = y_with_missing - y_pred_tree\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.histplot(residuals, kde=True, bins=30, color='skyblue')\n",
    "plt.axvline(0, color='red', linestyle='--')\n",
    "plt.xlabel(\"Resduos\")\n",
    "plt.title(\"Distribuio dos Resduos\")\n",
    "plt.show()\n",
    "\n",
    "# -------------------------------\n",
    "# 3 Importncia das Features\n",
    "# -------------------------------\n",
    "importances = pd.Series(best_tree_model.feature_importances_, index=X_tree.columns)\n",
    "importances = importances.sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.barplot(x=importances.values, y=importances.index, palette='viridis')\n",
    "plt.title(\"Importncia das Features - Decision Tree\")\n",
    "plt.xlabel(\"Importncia\")\n",
    "plt.ylabel(\"Features\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d81673f",
   "metadata": {},
   "source": [
    "#### HistGradientBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c939d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "param_grid_hist = {\n",
    "    'max_depth': [3, 5, 7, 10],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_iter': [100, 200, 300]\n",
    "}\n",
    "\n",
    "hist_model = HistGradientBoostingRegressor(random_state=42)\n",
    "grid_search_hist = GridSearchCV(\n",
    "    hist_model,\n",
    "    param_grid_hist,\n",
    "    cv=5,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search_hist.fit(X_with_missing, y_with_missing)\n",
    "\n",
    "print(f\"\\nBest Parameters: {grid_search_hist.best_params_}\")\n",
    "print(f\"Best CV MSE: {-grid_search_hist.best_score_:.4f}\")\n",
    "\n",
    "best_hist_model = grid_search_hist.best_estimator_\n",
    "y_pred_hist = best_hist_model.predict(X_with_missing)\n",
    "\n",
    "mse_hist = mean_squared_error(y_with_missing, y_pred_hist)\n",
    "cmse_hist = error_metric(y_with_missing, y_pred_hist, censored_with_missing)\n",
    "\n",
    "# cross_val_predict com o melhor modelo do GridSearchCV\n",
    "y_pred_cv = cross_val_predict(best_hist_model, X_with_missing, y_with_missing, cv=5)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# -------------------------------\n",
    "# 1 Predies vs Valores Observados (treino)\n",
    "# -------------------------------\n",
    "plt.figure(figsize=(6,6))\n",
    "sns.scatterplot(x=y_with_missing, y=y_pred_hist, alpha=0.6)\n",
    "plt.plot([y_with_missing.min(), y_with_missing.max()],\n",
    "         [y_with_missing.min(), y_with_missing.max()],\n",
    "         color='red', linestyle='--')\n",
    "plt.xlabel(\"Valores Observados\")\n",
    "plt.ylabel(\"Valores Preditos (Treino)\")\n",
    "plt.title(\"HistGradientBoosting: Observados vs Preditos (Treino)\")\n",
    "plt.show()\n",
    "\n",
    "# -------------------------------\n",
    "# 2 Predies vs Valores Observados (cross_val_predict)\n",
    "# -------------------------------\n",
    "plt.figure(figsize=(6,6))\n",
    "sns.scatterplot(x=y_with_missing, y=y_pred_cv, alpha=0.6, color='orange')\n",
    "plt.plot([y_with_missing.min(), y_with_missing.max()],\n",
    "         [y_with_missing.min(), y_with_missing.max()],\n",
    "         color='red', linestyle='--')\n",
    "plt.xlabel(\"Valores Observados\")\n",
    "plt.ylabel(\"Valores Preditos (CV)\")\n",
    "plt.title(\"HistGradientBoosting: Observados vs Preditos (CV)\")\n",
    "plt.show()\n",
    "\n",
    "# -------------------------------\n",
    "# 3 Resduos (Treino)\n",
    "# -------------------------------\n",
    "residuals_train = y_with_missing - y_pred_hist\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.histplot(residuals_train, kde=True, bins=30, color='skyblue')\n",
    "plt.axvline(0, color='red', linestyle='--')\n",
    "plt.xlabel(\"Resduos (Treino)\")\n",
    "plt.title(\"Distribuio dos Resduos - HistGradientBoosting\")\n",
    "plt.show()\n",
    "\n",
    "# -------------------------------\n",
    "# 4 Resduos (CV)\n",
    "# -------------------------------\n",
    "residuals_cv = y_with_missing - y_pred_cv\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.histplot(residuals_cv, kde=True, bins=30, color='orange')\n",
    "plt.axvline(0, color='red', linestyle='--')\n",
    "plt.xlabel(\"Resduos (CV)\")\n",
    "plt.title(\"Distribuio dos Resduos - HistGradientBoosting (CV)\")\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49d6120",
   "metadata": {},
   "source": [
    "#### CatBoost (Standart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2b68ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "# Define hyperparameter grid\n",
    "param_grid_catboost = {\n",
    "        'depth': [4, 6, 8, 10],\n",
    "        'learning_rate': [0.01, 0.05, 0.1],\n",
    "        'iterations': [100, 200, 300]\n",
    "    }\n",
    "    \n",
    "    # Grid search with cross-validation\n",
    "print(\"Performing Grid Search for CatBoostRegressor...\")\n",
    "catboost_model = CatBoostRegressor(random_state=42, verbose=False)\n",
    "grid_search_catboost = GridSearchCV(\n",
    "        catboost_model,\n",
    "        param_grid_catboost,\n",
    "        cv=5,\n",
    "        scoring='neg_mean_squared_error',\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "grid_search_catboost.fit(X_with_missing, y_with_missing)\n",
    "    \n",
    "print(f\"\\nBest Parameters: {grid_search_catboost.best_params_}\")\n",
    "print(f\"Best CV MSE: {-grid_search_catboost.best_score_:.4f}\")\n",
    "    \n",
    "    # Train final model\n",
    "best_catboost_model = grid_search_catboost.best_estimator_\n",
    "y_pred_catboost = best_catboost_model.predict(X_with_missing)\n",
    "    \n",
    "    # Evaluate\n",
    "mse_catboost = mean_squared_error(y_with_missing, y_pred_catboost)\n",
    "cmse_catboost = error_metric(y_with_missing, y_pred_catboost, censored_with_missing)\n",
    "    \n",
    "print(f\"\\nCatBoost Performance:\")\n",
    "print(f\"Training MSE:  {mse_catboost:.4f}\")\n",
    "print(f\"Training cMSE: {cmse_catboost:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "sns.scatterplot(x=y_with_missing, y=y_pred_catboost, alpha=0.6)\n",
    "plt.plot([y_with_missing.min(), y_with_missing.max()],\n",
    "         [y_with_missing.min(), y_with_missing.max()],\n",
    "         color='red', linestyle='--')\n",
    "plt.xlabel(\"Valores Observados\")\n",
    "plt.ylabel(\"Valores Preditos\")\n",
    "plt.title(\"CatBoostRegressor: Observados vs Preditos\")\n",
    "plt.show()\n",
    "\n",
    "# -------------------------------\n",
    "# 2 Resduos\n",
    "# -------------------------------\n",
    "residuals_catboost = y_with_missing - y_pred_catboost\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.histplot(residuals_catboost, kde=True, bins=30, color='skyblue')\n",
    "plt.axvline(0, color='red', linestyle='--')\n",
    "plt.xlabel(\"Resduos\")\n",
    "plt.title(\"Distribuio dos Resduos - CatBoostRegressor\")\n",
    "plt.show()\n",
    "\n",
    "# -------------------------------\n",
    "# 3 Importncia das Features\n",
    "# -------------------------------\n",
    "importances = pd.Series(best_catboost_model.feature_importances_, index=X_with_missing.columns)\n",
    "importances = importances.sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.barplot(x=importances.values, y=importances.index, palette='viridis')\n",
    "plt.title(\"Importncia das Features - CatBoostRegressor\")\n",
    "plt.xlabel(\"Importncia\")\n",
    "plt.ylabel(\"Features\")\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c595be",
   "metadata": {},
   "source": [
    "#### CatBoost (AFT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f649a93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "train_path = \"data/train_data.csv\"\n",
    "test_path = \"data/test_data.csv\"\n",
    "\n",
    "train_data = pd.read_csv(train_path)\n",
    "test_data = pd.read_csv(test_path)\n",
    "\n",
    "train_data = train_data.dropna(subset=['SurvivalTime', 'Censored'])\n",
    "\n",
    "train_data['y_lower'] = train_data['SurvivalTime']\n",
    "train_data['y_upper'] = np.where(train_data['Censored'] == 1, train_data['SurvivalTime'], -1)\n",
    "\n",
    "train_data = train_data.dropna(subset=['y_lower', 'y_upper'])\n",
    "\n",
    "train, valid = train_test_split(train_data, test_size=0.2, random_state=42)\n",
    "\n",
    "features = train.columns.difference(['SurvivalTime', 'Censored', 'y_lower', 'y_upper'], sort=False)\n",
    "\n",
    "categorical_features = []\n",
    "train_pool = Pool(train[features], label=train[['y_lower', 'y_upper']], cat_features=categorical_features)\n",
    "valid_pool = Pool(valid[features], label=valid[['y_lower', 'y_upper']], cat_features=categorical_features)\n",
    "\n",
    "model = CatBoostRegressor(\n",
    "    iterations=1000,\n",
    "    learning_rate=0.01,\n",
    "    depth=8,\n",
    "    loss_function='SurvivalAft:dist=Normal',\n",
    "    eval_metric='SurvivalAft',\n",
    "    verbose=50\n",
    ")\n",
    "\n",
    "model.fit(train_pool, eval_set=valid_pool)\n",
    "\n",
    "valid_predictions = model.predict(valid_pool, prediction_type='Exponent')\n",
    "\n",
    "valid_true = valid['y_lower']\n",
    "mse = mean_squared_error(valid_true, valid_predictions)\n",
    "print(f\"\\nMean Squared Error on Validation Set: {mse:.4f}\")\n",
    "\n",
    "test_pool = Pool(test_data[features], cat_features=categorical_features)\n",
    "\n",
    "test_predictions = model.predict(test_pool, prediction_type='Exponent')\n",
    "\n",
    "submission = pd.DataFrame({'id': test_data['id'], 'PredictedSurvivalTime': test_predictions})\n",
    "submission.to_csv('CatBoost_SurvivalAFT_submission.csv', index=False)\n",
    "print(\"\\nPredictions saved to 'CatBoost_SurvivalAFT_submission.csv'.\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(valid_true, valid_predictions, alpha=0.5, label=\"Predicted vs Actual\")\n",
    "plt.plot([valid_true.min(), valid_true.max()],\n",
    "         [valid_true.min(), valid_true.max()],\n",
    "         'k--', lw=2, label=\"Perfect Prediction\")\n",
    "plt.xlabel('Actual Survival Time (y)')\n",
    "plt.ylabel('Predicted Survival Time (y_hat)')\n",
    "plt.title('y vs. y_hat Plot - CatBoostRegressor (SurvivalAFT)')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# -------------------------------\n",
    "# 2 Resduos\n",
    "# -------------------------------\n",
    "residuals = valid_true - valid_predictions\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.histplot(residuals, bins=30, kde=True, color='skyblue')\n",
    "plt.axvline(0, color='red', linestyle='--')\n",
    "plt.xlabel('Residuals')\n",
    "plt.title('Residuals Distribution - CatBoost AFT')\n",
    "plt.show()\n",
    "\n",
    "# -------------------------------\n",
    "# 3 Distribuio de Predies\n",
    "# -------------------------------\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.histplot(valid_predictions, bins=30, kde=True, color='orange')\n",
    "plt.xlabel('Predicted Survival Time (y_hat)')\n",
    "plt.title('Distribution of Predicted Survival Times - CatBoost AFT')\n",
    "plt.show()\n",
    "\n",
    "# -------------------------------\n",
    "# 4 Feature Importance\n",
    "# -------------------------------\n",
    "feature_importances = model.get_feature_importance(train_pool)\n",
    "importance_df = pd.DataFrame({'feature': features, 'importance': feature_importances})\n",
    "importance_df = importance_df.sort_values(by='importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.barplot(x='importance', y='feature', data=importance_df, palette='viridis')\n",
    "plt.title('Feature Importance - CatBoost AFT')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07d6c48",
   "metadata": {},
   "source": [
    "#### Code Comparison ( isto e para a task3.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ea80d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 6. Model Comparison\n",
    "# ============================================================================\n",
    "\n",
    "# print(\"\\n\" + \"=\" * 88)\n",
    "# print(\"MODEL COMPARISON - Task 3.2\")\n",
    "# print(\"=\" * 88)\n",
    "\n",
    "# comparison_task3_2 = []\n",
    "\n",
    "# # Previous models (for reference)\n",
    "# comparison_task3_2.append({\n",
    "#     'Model': 'Baseline (Task 1.2)',\n",
    "#     'Method': 'Drop missing data',\n",
    "#     'MSE': mse_baseline,\n",
    "#     'cMSE': cmse_baseline\n",
    "# })\n",
    "\n",
    "# comparison_task3_2.append({\n",
    "#     'Model': 'Mean Imputation (Task 3.1)',\n",
    "#     'Method': 'Mean imputation',\n",
    "#     'MSE': mse_mean,\n",
    "#     'cMSE': 'N/A'\n",
    "# })\n",
    "\n",
    "# # Task 3.2 models\n",
    "# comparison_task3_2.append({\n",
    "#     'Model': 'Decision Tree',\n",
    "#     'Method': 'Missing as -999',\n",
    "#     'MSE': mse_tree,\n",
    "#     'cMSE': cmse_tree\n",
    "# })\n",
    "\n",
    "# comparison_task3_2.append({\n",
    "#     'Model': 'HistGradientBoosting',\n",
    "#     'Method': 'Native missing support',\n",
    "#     'MSE': mse_hist,\n",
    "#     'cMSE': cmse_hist\n",
    "# })\n",
    "\n",
    "# if catboost_available:\n",
    "#     comparison_task3_2.append({\n",
    "#         'Model': 'CatBoost Standard',\n",
    "#         'Method': 'Native missing support',\n",
    "#         'MSE': mse_catboost,\n",
    "#         'cMSE': cmse_catboost\n",
    "#     })\n",
    "    \n",
    "    \n",
    "\n",
    "# df_comparison_task3_2 = pd.DataFrame(comparison_task3_2)\n",
    "# print(\"\\n\" + df_comparison_task3_2.to_string(index=False))\n",
    "# print(\"=\" * 88)\n",
    "\n",
    "# ============================================================================\n",
    "# 7. Visualization - Predictions Comparison\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nGenerating visualization plots...\")\n",
    "\n",
    "# Determine number of subplots\n",
    "n_models = 4\n",
    "n_cols = 2\n",
    "n_rows = int(np.ceil(n_models / n_cols))\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(12, 5*n_rows))\n",
    "fig.patch.set_facecolor('white')\n",
    "\n",
    "if n_rows == 1:\n",
    "    axes = axes.reshape(1, -1)\n",
    "\n",
    "axes = axes.flatten()\n",
    "\n",
    "plot_idx = 0\n",
    "\n",
    "# Plot 1: Decision Tree\n",
    "axes[plot_idx].scatter(y_with_missing, y_pred_tree, alpha=0.5, color='brown')\n",
    "axes[plot_idx].plot([y_with_missing.min(), y_with_missing.max()], \n",
    "             [y_with_missing.min(), y_with_missing.max()], 'r--', lw=2)\n",
    "axes[plot_idx].set_xlabel('True Survival Time')\n",
    "axes[plot_idx].set_ylabel('Predicted Survival Time')\n",
    "axes[plot_idx].set_title(f'Decision Tree\\nMSE: {mse_tree:.4f} | cMSE: {cmse_tree:.4f}')\n",
    "axes[plot_idx].grid(True, alpha=0.3)\n",
    "plot_idx += 1\n",
    "\n",
    "# Plot 2: HistGradientBoosting\n",
    "axes[plot_idx].scatter(y_with_missing, y_pred_hist, alpha=0.5, color='blue')\n",
    "axes[plot_idx].plot([y_with_missing.min(), y_with_missing.max()], \n",
    "             [y_with_missing.min(), y_with_missing.max()], 'r--', lw=2)\n",
    "axes[plot_idx].set_xlabel('True Survival Time')\n",
    "axes[plot_idx].set_ylabel('Predicted Survival Time')\n",
    "axes[plot_idx].set_title(f'HistGradientBoosting\\nMSE: {mse_hist:.4f} | cMSE: {cmse_hist:.4f}')\n",
    "axes[plot_idx].grid(True, alpha=0.3)\n",
    "plot_idx += 1\n",
    "\n",
    "if catboost_available:\n",
    "    # Plot 3: CatBoost Standard\n",
    "    axes[plot_idx].scatter(y_with_missing, y_pred_catboost, alpha=0.5, color='green')\n",
    "    axes[plot_idx].plot([y_with_missing.min(), y_with_missing.max()], \n",
    "                        [y_with_missing.min(), y_with_missing.max()], 'r--', lw=2)\n",
    "    axes[plot_idx].set_xlabel('True Survival Time')\n",
    "    axes[plot_idx].set_ylabel('Predicted Survival Time')\n",
    "    axes[plot_idx].set_title(f'CatBoost Standard\\nMSE: {mse_catboost:.4f} | cMSE: {cmse_catboost:.4f}')\n",
    "    axes[plot_idx].grid(True, alpha=0.3)\n",
    "    plot_idx += 1\n",
    "\n",
    "    # Plot 4: CatBoost AFT\n",
    "    axes[plot_idx].scatter(y_with_missing, y_pred_aft, alpha=0.5, color='purple')\n",
    "    axes[plot_idx].plot([y_with_missing.min(), y_with_missing.max()], \n",
    "                        [y_with_missing.min(), y_with_missing.max()], 'r--', lw=2)\n",
    "    axes[plot_idx].set_xlabel('True Survival Time')\n",
    "    axes[plot_idx].set_ylabel('Predicted Survival Time')\n",
    "    axes[plot_idx].set_title(f'CatBoost AFT\\nMSE: {mse_aft:.4f} | cMSE: {cmse_aft:.4f}')\n",
    "    axes[plot_idx].grid(True, alpha=0.3)\n",
    "\n",
    "    \n",
    "   \n",
    "\n",
    "# Hide unused subplots\n",
    "for idx in range(plot_idx, len(axes)):\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('./plots/task3_2_model_predictions.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Saved prediction plots for {plot_idx} models\")\n",
    "\n",
    "# ============================================================================\n",
    "# 8. Generate Submission File\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Generating Submission File for Task 3.2\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Load test data\n",
    "df_test_task3_2 = pd.read_csv('./data/test_data.csv')\n",
    "X_test_task3_2 = df_test_task3_2.drop(['id'], axis=1)\n",
    "X_test_tree = X_test_task3_2.fillna(-999)\n",
    "\n",
    "# Determine best model based on cMSE\n",
    "models_results = {\n",
    "    'Decision Tree': (cmse_tree, best_tree_model.predict(X_test_tree)),\n",
    "    'HistGradientBoosting': (cmse_hist, best_hist_model.predict(X_test_task3_2))\n",
    "}\n",
    "\n",
    "if catboost_available:\n",
    "    models_results['CatBoost Standard'] = (cmse_catboost, best_catboost_model.predict(X_test_task3_2))\n",
    "\n",
    "# Find best model\n",
    "best_model_name = min(models_results, key=lambda k: models_results[k][0])\n",
    "best_cmse = models_results[best_model_name][0]\n",
    "best_predictions_task3_2 = models_results[best_model_name][1]\n",
    "\n",
    "print(f\"Best model selected: {best_model_name}\")\n",
    "print(f\"Best cMSE: {best_cmse:.4f}\")\n",
    "print(\"\\nAll model cMSE scores:\")\n",
    "for model_name, (cmse, _) in sorted(models_results.items(), key=lambda x: x[1][0]):\n",
    "    print(f\"  {model_name}: {cmse:.4f}\")\n",
    "\n",
    "# Create submission file\n",
    "create_submission_file(best_predictions_task3_2, 'task3_2-submission-01.csv')\n",
    "\n",
    "print(f\"\\nPredictions generated for {len(best_predictions_task3_2)} test samples\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TASK 3.2 COMPLETED!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aa-project-2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
