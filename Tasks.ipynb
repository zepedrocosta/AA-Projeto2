{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51f4da44",
   "metadata": {},
   "source": [
    "# Project 2 - Multiple Myeloma Survival\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7d8e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import missingno as msno\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a78a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8987bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_submission_file(predictions, filename):\n",
    "    \"\"\"\n",
    "    Create a submission file with predictions.\n",
    "    \n",
    "    Args:\n",
    "        predictions (array-like): The predicted values for SurvivalTime.\n",
    "        filename (str): The name of the output file.\n",
    "    \"\"\"\n",
    "    # Load the sample submission to get the 'Id' column structure\n",
    "    sample_submission = pd.read_csv('./data/sample_submission.csv')\n",
    "\n",
    "    # Ensure that predictions are a single column (reshape if necessary)\n",
    "    predictions = pd.Series(predictions).values\n",
    "    \n",
    "    # Create the submission DataFrame\n",
    "    submission = pd.DataFrame(columns=sample_submission.columns) \n",
    "    submission['SurvivalTime'] = predictions  # Add the predictions to the 'SurvivalTime' column\n",
    "\n",
    "    # Save the DataFrame to CSV\n",
    "    os.makedirs(\"./results\", exist_ok=True)\n",
    "    submission.to_csv(f'./results/{filename}', index=False)\n",
    "\n",
    "    print(f\"File Created: ./results/{filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66d528f",
   "metadata": {},
   "source": [
    "## Task 1 - Setting the baseline\n",
    "\n",
    "### Task 1.1 - Data preparation and validation pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33500ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple visualization of missing values\n",
    "\n",
    "msno.bar(df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ee200c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple visualization of missing values\n",
    "\n",
    "msno.heatmap(df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1854e228",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple visualization of missing values\n",
    "\n",
    "msno.matrix(df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364bcd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple visualization of missing values\n",
    "\n",
    "msno.dendrogram(df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0e6cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing 'SurvivalTime' values\n",
    "df_cleaned = df[df['SurvivalTime'].notnull()]\n",
    "\n",
    "# Drop columns with missing data (for the baseline task 1.1)\n",
    "df_cleaned = df_cleaned.dropna(axis=1)  # Drop columns with any missing data\n",
    "\n",
    "# Drop rows where 'Censored' is 1 (Censoring occurs when the exact time of an event of interest (such as death or disease recurrence) is unknown)\n",
    "df_cleaned = df_cleaned[(df_cleaned['Censored']== 0)]\n",
    "\n",
    "#answering how many data points remain after dropping?\n",
    "print(f\"Remaining data points after dropping: {df_cleaned.shape[0]}\")\n",
    "\n",
    "\n",
    "msno.matrix(df_cleaned)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77812ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scattter plots and diagonal histograms\n",
    "\n",
    "#we dont put here the Censored because its a label indicator(which is not a feature for prediction, but a flag for censoring)\n",
    "sns.pairplot(df_cleaned, vars=['Age', 'Gender', 'Stage','TreatmentType', 'SurvivalTime'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c57bc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the feature matrix (X) and target vector (y)\n",
    "X = df_cleaned.drop(['SurvivalTime', 'Censored'], axis=1)  # Drop target and censoring indicator\n",
    "y = df_cleaned['SurvivalTime']  # Target variable: survival time\n",
    "censored = df_cleaned['Censored']  # Censoring indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65d8d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#80% training and 20% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# split training data into 80% training and 20% validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6032f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = LinearRegression()\n",
    "model1.fit(X_train, y_train)\n",
    "\n",
    "# Step 4: Evaluate on the validation set\n",
    "y_val_pred = model1.predict(X_val)\n",
    "val_mse = mean_squared_error(y_val, y_val_pred)\n",
    "print(f'Validation Mean Squared Error: {val_mse}')\n",
    "\n",
    "# Step 5: Test the model on the test set\n",
    "y_test_pred = model1.predict(X_test)\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "print(f'Test Mean Squared Error: {test_mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d306c832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can improve cv\n",
    "# Use cross-validation with a linear regression model\n",
    "model = LinearRegression()\n",
    "cv_scores = cross_val_score(model, X, y, cv=5)  # 5-fold cross-validation with default scoring (R^2)\n",
    "print(f\"Cross-validation scores: {cv_scores}\")\n",
    "\n",
    "average_cv_score = np.mean(cv_scores)\n",
    "print(f\"Average Cross-validation Score: {average_cv_score}\")\n",
    "\n",
    "# Step 6: Train the model on the full dataset and test on a holdout test set (optional)\n",
    "# If you still want to do a final test evaluation, split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_val_pred = model.predict(X_val)\n",
    "val_mse = mean_squared_error(y_val, y_val_pred)\n",
    "print(f\"Validation MSE: {val_mse}\")\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_test_pred = model.predict(X_test)\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "print(f\"Test MSE: {test_mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef131ad",
   "metadata": {},
   "source": [
    "Comparing the Avarage MSE Cross validation value and the MSE value simple, with Cross Validation is more efficient without Cross Validation because in cross-validation, the model is trained and validated multiple times using different splits of the dataset. This means that the model gets to train on almost all of the data, which helps the model generalize better.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78566156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Censored Mean Squared Error(we used this because for the censored cases we only know that the survival time is greater than some observed time)\n",
    "# c = 0 for uncensored data points\n",
    "# c = 1 for censored data points\n",
    "\n",
    "def error_metric(y, y_hat, c):\n",
    "    import numpy as np\n",
    "    err = y-y_hat\n",
    "    err = (1-c)*err**2 + c*np.maximum(0,err)**2\n",
    "    return np.sum(err)/err.shape[0]\n",
    "\n",
    "# c is the censored variable \n",
    "#  y is the true Survival Time, as determined by the ground truth.\n",
    "#  The variable y_hat contains the predicted Survival Time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a3ed12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Censored Mean Squared Error \n",
    "\n",
    "# Without cross-validation\n",
    "print(\"Without cross-validation\")\n",
    "y_val_pred = model1.predict(X_val)\n",
    "val_cmse = error_metric(y_val, y_val_pred,censored)\n",
    "print(f'Validation cMSE: {val_cmse}')\n",
    "\n",
    "y_test_pred = model1.predict(X_test)\n",
    "test_cmse = error_metric(y_test, y_test_pred,censored)\n",
    "print(f'Test cMSE: {test_cmse}\\n')\n",
    "\n",
    "\n",
    "#With cross-validation\n",
    "print(\"With cross-validation\")\n",
    "y_val_pred = model.predict(X_val)\n",
    "val_cmse = error_metric(y_val, y_val_pred,censored)\n",
    "print(f\"Validation cMSE: {val_cmse}\")\n",
    "\n",
    "y_test_pred = model.predict(X_test)\n",
    "test_cmse = error_metric(y_test, y_test_pred,censored)\n",
    "print(f\"Test cMSE: {test_cmse}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45980a16",
   "metadata": {},
   "source": [
    "we saw without cross-validation validation worst then test because of 2 possible reasons. Overfitting of the Valisdation Set or Random variablity in a single train/test split. Shows again that with cross-validation we try to coverage this cases with that solution. \n",
    "\n",
    "Note: we can change the split percentage to see if we can have a better result without cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f2639e",
   "metadata": {},
   "source": [
    "### Task 1.2 - Learn the baseline model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7554c1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the pipeline with scaling and Linear Regression\n",
    "pipeline = make_pipeline(\n",
    "    StandardScaler(),  # Feature scaling\n",
    "    LinearRegression()  # Linear regression model\n",
    ")\n",
    "\n",
    "# first try with r^2\n",
    "cv_scores = cross_val_score(pipeline, X, y, cv=5)  # 5-fold cross-validation\n",
    "\n",
    "\n",
    "pipeline.fit(X, y)\n",
    "y_pred = pipeline.predict(X)\n",
    "\n",
    "\n",
    "mse = mean_squared_error(y, y_pred)\n",
    "print(f\"MSE: {mse}\")\n",
    "cMSE = error_metric(y, y_pred,censored)\n",
    "print(f\"cMSE: {cMSE}\")\n",
    "\n",
    "create_submission_file(y_pred, 'baseline-submission-01.csv')\n",
    "\n",
    "plt.scatter(y, y_pred)\n",
    "plt.xlabel('True Values (y)')\n",
    "plt.ylabel('Predicted Values (y_hat)')\n",
    "plt.title('True vs Predicted Survival Time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f7ed9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot([y, y_pred], tick_labels=[\"True Values\", \"Predicted Values\"])\n",
    "plt.title(\"Boxplot of True vs Predicted Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3adbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the unique values in the 'Censored' column\n",
    "print(df_cleaned['Censored'].value_counts())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
